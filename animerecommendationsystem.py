# -*- coding: utf-8 -*-
"""AnimeRecommendationSystem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wPwIBm--3k2F6WcsiRctymC10zxuEx7G

# Proyek Sistem Rekomendasi : Sistem rekomendasi Anime
- Nama : Andi Sadapotto
- Email : andi.sadapotto.m@gmail.com
- ID Dicoding : andi_sadapotto

install library pendukung
"""

!pip install fake-useragent
!pip install scikit-surprise

"""## Import package & library"""

import seaborn as sns
import pandas as pd
import requests
import shutil
import numpy as np
import os
import zipfile
import tensorflow as tf


from PIL import Image, UnidentifiedImageError
from matplotlib import pyplot as plt
from surprise import Dataset, Reader, SVD
from surprise.model_selection import train_test_split as surprise_train_test_split
from surprise import accuracy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split

"""## Data Loading

### Download dan ekstrak dataset
Download dataset dari sistus penyedia kaggle kemudian mengekstrak dan menyimpan dataset kedalam folder dataset
"""

# Download  dataset
!curl -L -o archive.zip https://www.kaggle.com/api/v1/datasets/download/marlesson/myanimelist-dataset-animes-profiles-reviews

# Ekstrak  dataset
with zipfile.ZipFile('archive.zip', 'r') as zip_ref:
    zip_ref.extractall('dataset')  # Ekstrak ke folder 'dataset'

# Hapus file zipe
os.remove('archive.zip')

#Tampilkan list konten dari folder 'dataset'
!ls -l dataset

"""### Load dataset

load semua file dataset
"""

df_anime = pd.read_csv('dataset/animes.csv')
df_review = pd.read_csv('dataset/reviews.csv')
df_user = pd.read_csv('dataset/profiles.csv')

"""## Data Undestanding

Menampilkan jumlah baris dan kolom tiap dataset
"""

# Tampilkan jumlah data dan kolom untuk masing-masing dataset
print("Jumlah data dan kolom df_anime:")
print(df_anime.shape)
print("\nJumlah data dan kolom df_review:")
print(df_review.shape)
print("\nJumlah data dan kolom df_user:")
df_user.shape

"""Menampilkan list variabel tiap dataset"""

print("List variabel df_anime:")
print(df_anime.columns.tolist())
print("\nList variabel df_review:")
print(df_review.columns.tolist())
print("\nList variabel df_user:")
print(df_user.columns.tolist())

"""### Variabel Description

animes.csv memiliki 19311 baris dan 12 kolom dengan deskripsi sebagai berikut

Variable | Keterangan
------|------
uid| Kode unik untuk tiap anime
title| Judul dari anime
synopsis| Ringkasan atau ikhtisar dari sebuah anime
genre| List genre dari anime
aired| Tanggal tayang
episodes| Jumlah episode
members| Total member pada komunitas
popularity| Popularitas di situs MyAnimelist
ranked| Rangking/peringkat di situs MyAnimelist
score| Skor/rating di situs MyAnimelist
img_url|link thumbnail anime
link|link anime di MyAnimelist

reviews.csv memiliki 192112 baris dan 7 kolom dengan deskripsi sebagai berikut

Variable | Keterangan
------|------
uid| id unik untuk masing-masing review
profile| username dari pengguna yang memberikan review
anime_uid| anime uid yang di review
text| text review
score| overall skor review yang diberikan
scores |detail score yang diberikan
link| link detail review

profiles.csv memiliki 81727 baris dan 5 kolom dengan deskripsi sebagai berikut

Variable | Keterangan
------|------
profile | username unik untuk tiap pengguna
gender | jenis kelamin
birthday | tanggal lahir
favorites_anime | list anime favorit
link | link profil pengguna

### Assesing Data

Cek missing value

cek missing value anime
"""

df_anime.isnull().sum()

"""cek missing value review"""

df_review.isnull().sum()

"""cek missing value user/profile"""

df_user.isnull().sum()

"""Cek data duplicate"""

df_anime.duplicated().sum()

df_review.duplicated().sum()

df_user.duplicated().sum()

"""### Exploratory Data Analysis (EDA) & Visualisasi Data

#### Dataset Anime

ceck info variabel data frame anime
"""

df_anime.info()

"""Deskripsi statistik dataset anime"""

df_anime.describe(include='all')

"""Grouping berdasarkan genre"""

df_anime.groupby('genre').count().sort_values(by='uid', ascending=False)

"""tampilkan data berdasarkan rank"""

df_anime[['title','ranked']].sort_values(by='ranked', ascending=True)

"""tamplikan mode dari synopsis"""

df_anime.synopsis.mode()[0]

"""visualiasi distribusi anime berdasarkan score, top 10 anime terbanyak beserta genre, hubungan antar score dengan episodes, hubungan score dan member"""

# Create the figure and axes
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Plot 1: Distribution of Anime Scores
sns.histplot(df_anime['score'].dropna(), kde=True, ax=axes[0, 0])
axes[0, 0].set_title('Distribution of Anime Scores')

# Plot 2: Top 10 Genres
top_genres = df_anime.groupby('genre').size().sort_values(ascending=False).head(10)
sns.barplot(x=top_genres.index, y=top_genres.values, ax=axes[0, 1])
axes[0, 1].set_title('Top 10 Most Genres')
axes[0,1].tick_params(axis='x', rotation=45) # Rotate x-axis labels for better readability


# Plot 3: Relationship between Score and Number of Episodes
sns.scatterplot(x='episodes', y='score', data=df_anime.dropna(subset=['episodes', 'score']), ax=axes[1, 0])
axes[1, 0].set_title('Score vs. Number of Episodes')


# Plot 4: Relationship between Score and Members
sns.regplot(x='members', y='score', data=df_anime.dropna(subset=['members', 'score']), ax=axes[1, 1])
axes[1, 1].set_title('Score vs. Members')

# Adjust layout to prevent overlapping titles and labels
plt.tight_layout()

# Show the plot
plt.show()

"""#### Dataset review

cek info variabel review
"""

df_review.info()

"""Deskripsi statistik dataset anime"""

df_review.describe(include='all')

"""tampilkan grouping data review by scores"""

df_review.groupby('scores').count().sort_values(by='uid', ascending=False)

"""tampilkan data grouping review by profile"""

df_review.groupby('profile').count().sort_values(by='uid', ascending=False)

"""menampilkan distribusi review score, dan top 10 reviewers"""

# Create the figure and axes
fig, axes = plt.subplots(2, 1, figsize=(10, 6))

# Plot 1: Distribution of Review Scores
sns.histplot(df_review['score'].dropna(), kde=True, ax=axes[0])
axes[0].set_title('Distribution of Review Scores')

# Plot 2: Top 10 Reviewers
top_reviewers = df_review.groupby('profile').size().sort_values(ascending=False).head(10)
sns.barplot(x=top_reviewers.index, y=top_reviewers.values, ax=axes[1])
axes[1].set_title('Top 10 Reviewers')
axes[1].tick_params(axis='x', rotation=45) # Rotate x-axis labels


# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

"""#### Dataset profile/user

cek info variabel user
"""

df_user.info()

"""Deskripsi statistik dataset user"""

df_user.describe(include='all')

"""tampilkan data gender dari profile"""

df_user.groupby('gender').profile.nunique().sort_values(ascending=False)

"""cek missing valu dari variabel gender"""

df_user.gender.isnull().sum()

"""fungsi untuk melakukan pengecekan pada data user gender yang tidak konsisten"""

def check_gender_inconsistency(df):
  """
  Checks for inconsistencies in gender information within a DataFrame.

  Args:
    df: A pandas DataFrame containing a 'profile' column and a 'gender' column.

  Returns:
    A pandas Series with profile names that have inconsistent gender information,
    or None if no inconsistencies are found.
  """

  profiles_with_gender = df.dropna(subset=['gender'])['profile'].unique()
  profiles_without_gender = df[df['gender'].isna()]['profile'].unique()

  inconsistent_profiles = set(profiles_with_gender) & set(profiles_without_gender)

  if inconsistent_profiles:
    return pd.Series(list(inconsistent_profiles), name="Inconsistent Profiles")
  else:
    return None

inconsistent_genders = check_gender_inconsistency(df_user)

if inconsistent_genders is not None:
  print("Profiles with inconsistent gender information:")
  print(inconsistent_genders)
else:
  print("No inconsistencies in gender information found.")

"""menampilkan distribusi gender dan taggal lahir"""

# Create the figure and axes
fig, ax = plt.subplots(figsize=(8, 6))

# Plot the distribution of genders
sns.countplot(x='gender', data=df_user, ax=ax)
ax.set_title('Distribution of User Genders')
ax.set_xlabel('Gender')
ax.set_ylabel('Number of Users')

# Show the plot
plt.show()

#Distribution of users by birthday year
df_user['birthday'] = pd.to_datetime(df_user['birthday'], errors='coerce')
birthyear = df_user['birthday'].dt.year
plt.figure(figsize=(10,6))
sns.histplot(birthyear.dropna(), kde=True)
plt.title("Distribution of Users' Birth Year")
plt.xlabel('Birth Year')
plt.ylabel('Number of Users')
plt.show()

"""menampilkan data genre dengan score tertinggi dan yang paling banyak di review"""

# Group by genre and get the highest score and most reviews for each genre
genre_stats = df_anime.groupby('genre').agg(
    max_score=('score', 'max'),
    review_count=('uid', 'count')
).reset_index()

# Find the genre with the highest score
highest_score_genre = genre_stats.loc[genre_stats['max_score'].idxmax()]

# Find the genre with the most reviews
most_reviews_genre = genre_stats.loc[genre_stats['review_count'].idxmax()]

print("Genre with the highest score:")
highest_score_genre

print("Genre with the most reviews:")
most_reviews_genre

"""menampilkan list genre dengan score dan jumlah review"""

# Merge anime and review dataframes
merged_df = pd.merge(df_anime, df_review, left_on='uid', right_on='anime_uid', how='inner')

# Group by genre and calculate the average score and number of reviews
genre_performance = merged_df.groupby('genre').agg(
    avg_score=('score_y', 'mean'),
    num_reviews=('uid_y', 'count')
).reset_index()

# Sort by average score and number of reviews to find the most popular genres
genre_performance = genre_performance.sort_values(by=['avg_score', 'num_reviews'], ascending=False)

genre_performance

"""menampilkan top ten genre dengan score dan jumlah review tertinggi"""

# Filter genres with average score greater than 8
top_genres = genre_performance[genre_performance['avg_score'] > 8]

# Explode the 'genre' column to separate genres
top_genres['genre'] = top_genres['genre'].str.split(', ')
exploded_genres = top_genres.explode('genre')

# Count the occurrences of each genre
genre_counts = exploded_genres['genre'].value_counts()

# Get the top 10 genres
top_ten_genres = genre_counts.head(10)

top_ten_genres

"""menampilkan visualiasi dari top ten genre dengan score dan jumlah review tertinggi"""

# Create the bar plot for top_ten_genres
plt.figure(figsize=(10, 6))
sns.barplot(x=top_ten_genres.index, y=top_ten_genres.values)
plt.title('Top 10 Genres')
plt.xlabel('Genre')
plt.ylabel('Number of Animes')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()

"""## Data Preparation

menghapus data duplikat
"""

# drop duplicate colomn
df_anime.drop_duplicates(inplace=True)
df_review.drop_duplicates(inplace=True)
df_user.drop_duplicates(inplace=True)

"""menangani missing value pada variabel-variabel dataset"""

#fill missing value on dataset user
df_user['gender'].fillna('Non-Binary', inplace=True)

#fill missing value on birthday with interpolate
df_user['birthday'].fillna(df_user['birthday'].interpolate(), inplace=True)

# add column age based on birthday
df_user['birthday'] = pd.to_datetime(df_user['birthday'])
# Calculate age using days and dividing by 365.25 to approximate years
df_user['age'] = (pd.to_datetime('today') - df_user['birthday']).dt.days / 365.25
df_user['age'] = df_user['age'].astype(int)

# Fill missing values, incrementing the rank for each missing value
next_rank = df_anime['ranked'].max() + 1 if not pd.isna(df_anime['ranked'].max()) else 1

df_anime['ranked'] = df_anime['ranked'].fillna(next_rank + df_anime['ranked'].isnull().cumsum())
df_anime['ranked'] = df_anime['ranked'].astype(int)

# fill missing value on synopsis with mode
df_anime.synopsis.fillna(df_anime.synopsis.mode()[0], inplace=True)

# fill missing value on score with zero
df_anime.score.fillna(0, inplace=True)

# fill missing values episodes to -1
df_anime.episodes.fillna(-1, inplace=True)

"""menampilkan dataset anime setelah cleansing"""

df_anime

"""cek missing value dataset anime setelah cleansing"""

df_anime.isnull().sum()

"""menampilkan dataset user setelah cleansing"""

df_user

"""menampilkan dataset review setelah cleansing"""

df_review

"""menggabungkan dataset review dan anime"""

# prepare dataset for collaborative filtering

df_review_anime = df_review.copy()
df_review_anime.rename(columns={'score':'user_scored'}, inplace=True)
df_review_anime.drop(columns=['text','uid','scores','link'], inplace=True)
df_review_anime = pd.merge(df_review_anime, df_anime[['uid','title','genre','img_url','score']], left_on='anime_uid', right_on='uid', how='left')
df_review_anime

"""menampilkan missing value dataset review anime"""

df_review_anime.isnull().sum()

"""membuat tfidf matrix"""

# Create a TF-IDF vectorizer
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df_anime['genre'])

"""membuat encoding multilabelbinarizer pada variabel genre"""

from sklearn.preprocessing import MultiLabelBinarizer

mlb = MultiLabelBinarizer()
genre_encoded = mlb.fit_transform(df_review_anime['genre'].apply(lambda x: x.replace("[", "").replace("]", "").replace("'", "").split(", ")))

# Create a DataFrame for the encoded genres
genre_df = pd.DataFrame(genre_encoded, columns=mlb.classes_, index=df_review_anime.index)

# Concatenate the encoded genres with the existing DataFrame
df_review_anime = pd.concat([df_review_anime, genre_df], axis=1)

"""split dataset untuk model svd"""

# define rating scale
rating_scale = Reader(rating_scale=(0, 10))

# load data
data = Dataset.load_from_df(df_review_anime[['profile', 'title', 'user_scored',]], rating_scale)

# split dataset
train_set, test_set = surprise_train_test_split(data, test_size=0.20, random_state=42)

"""split dataset untuk model neural network embedding"""

# Convert categorical data (profile and title) to numerical representations
user_ids = df_review_anime['profile'].unique()
anime_ids = df_review_anime['title'].unique()

user_to_index = {user: index for index, user in enumerate(user_ids)}
anime_to_index = {anime: index for index, anime in enumerate(anime_ids)}

df_review_anime['user_index'] = df_review_anime['profile'].map(user_to_index)
df_review_anime['anime_index'] = df_review_anime['title'].map(anime_to_index)

# Prepare data for the model
X = df_review_anime[['user_index', 'anime_index']].values
y = df_review_anime['user_scored'].values.astype(float)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Modeling

### Content Based

fungsi untuk mencari top n anime dengan content based
"""

def content_based_recommender(df, title, top_n=10):
    df = df.copy()
    try:
      # Compute cosine similarity matrix
      cosine_sim = cosine_similarity(tfidf_matrix)

      # Get the index of the anime with the given title
      indices = pd.Series(df.index, index=df['title']).drop_duplicates()

      # Function that takes in anime title as input and outputs most similar anime
      idx = indices[title]
      sim_scores = list(enumerate(cosine_sim[idx]))
      sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
      sim_scores = sim_scores[1:top_n+1]  # Exclude the anime itself
      anime_indices = [i[0] for i in sim_scores]

      # Return recommended anime titles with similarity scores
      recommendations = df['title'].iloc[anime_indices].reset_index(drop=True)
      recommendations_df = pd.DataFrame({'title': recommendations, 'Similarity Score': [i[1] for i in sim_scores]})

      return recommendations_df

    except Exception as e:
      print(f"An error occurred: {e}")
      return FileNotFoundError

"""menampilkan top n anime dengan content based"""

from fake_useragent import UserAgent

ua = UserAgent()

n=10
top_ten=content_based_recommender(df_anime, 'Naruto', top_n=n)
fig,ax=plt.subplots(1,10,figsize=(17,5))
fig.suptitle("Try these anime",fontsize=40)
if top_ten is None:
    print("No recommendations found.")
else:
  for i in range(len(top_ten["title"].tolist())):
      url=df_anime.loc[df_anime["title"]==top_ten["title"].tolist()[i],"img_url"][:1].values[0]
      try:
          headers = {'User-Agent': ua.random}
          response = requests.get(url, stream=True, headers=headers)
          response.raise_for_status()  # Raise an exception for bad responses (4xx or 5xx)
          img = Image.open(response.raw)
      except requests.exceptions.RequestException as e:
          print(f"Error downloading image from {url}: {e}")
          continue  # Skip to the next image if download fails
      except UnidentifiedImageError as e:
          print(f"Error opening image from {url}: {e}")
          continue  # Skip to the next image if opening fails
      except Exception as e:
          print(f"An unexpected error occurred: {e}")
          continue  # Skip to the next image if any other error occurs
      ax[i].imshow(img)
      ax[i].axis("off")
      ax[i].set_title("Score: {}".format(round(df_anime[df_anime["title"]==top_ten["title"].tolist()[i]]["score"].mean(),1)),y=-0.20,fontsize=10)
      fig.show()

"""### Colaborative filtering

#### SVD

inisiasi model svd
"""

model_svd = SVD()

"""melatih model svd"""

model_svd.fit(train_set)

"""melakukan prediksi model svd pada data test"""

predictions_svd = model_svd.test(test_set)

"""fungsi untuk memprediksi top n anime dengan model svd"""

def collaborative_recommender(df, profile, top_n=10):
  all_anime = df['title'].unique()
  rated_anime = df[df['profile'] == profile]['title'].unique()
  unrated_anime = np.setdiff1d(all_anime, rated_anime)
  predictions = [model_svd.predict(profile, anime) for anime in unrated_anime]
  predictions.sort(key=lambda x: x.est, reverse=True)
  top_n_predictions = predictions[:top_n]
  return [(pred.iid, pred.est) for pred in top_n_predictions]

"""menampilkan top n anime dengan model svd"""

top_ten=collaborative_recommender(df_review_anime, 'Yuez', top_n=10)

fig,ax=plt.subplots(1,10,figsize=(17,5))
fig.suptitle("Try these anime",fontsize=40)
if top_ten is None:
    print("No recommendations found.")
else:
  for i in range(len(top_ten)):
      title = top_ten[i][0]
      url=df_review_anime.loc[df_review_anime["title"]==title,"img_url"][:1].values[0]

      try:
          headers = {'User-Agent': ua.random}
          response = requests.get(url, stream=True, headers=headers)
          response.raise_for_status()  # Raise an exception for bad responses (4xx or 5xx)
          img = Image.open(response.raw)
      except requests.exceptions.RequestException as e:
          print(f"Error downloading image from {url}: {e}")
          continue  # Skip to the next image if download fails
      except UnidentifiedImageError as e:
          print(f"Error opening image from {url}: {e}")
          continue  # Skip to the next image if opening fails
      except Exception as e:
          print(f"An unexpected error occurred: {e}")
          continue  # Skip to the next image if any other error occurs
      ax[i].imshow(img)
      ax[i].axis("off")
      ax[i].set_title("Score: {}".format(round(df_anime[df_anime["title"]==title]["score"].mean(),1)),y=-0.20,fontsize=10)
      fig.show()

"""#### Neural network

membuat model neural network dengan keras model
"""

# Input for user index
user_input = tf.keras.layers.Input(shape=(1,))
user_embedding = tf.keras.layers.Embedding(len(user_ids), 64)(user_input)
user_embedding = tf.keras.layers.Flatten()(user_embedding)

# Input for genre features
genre_input = tf.keras.layers.Input(shape=(genre_encoded.shape[1],))  # Shape based on encoded genre features

# Concatenate user and genre features
merged_features = tf.keras.layers.concatenate([user_embedding, genre_input])

# Hidden layers with regularization and dropout
hidden_layer1 = tf.keras.layers.Dense(512, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.005))(merged_features)
hidden_layer1 = tf.keras.layers.Dropout(0.4)(hidden_layer1)
hidden_layer2 = tf.keras.layers.Dense(256, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01))(hidden_layer1)
hidden_layer2 = tf.keras.layers.Dropout(0.2)(hidden_layer2)  # Add dropout
hidden_layer3 = tf.keras.layers.Dense(128, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01))(hidden_layer2)
hidden_layer3 = tf.keras.layers.Dropout(0.2)(hidden_layer3)  # Add dropout

# Output layer
output = tf.keras.layers.Dense(1)(hidden_layer3)

# Create the model
model = tf.keras.Model(inputs=[user_input, genre_input], outputs=output)

"""inisiasi callback"""

# define callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
reduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)

"""compile model"""

# Compile the model
model.compile(
      optimizer='sgd',
      loss= 'mae',
      metrics= ['mae'],
    )

"""training model"""

# Prepare training data
X_train_user = X_train[:, 0].reshape(-1, 1)  # User index
X_train_genre = df_review_anime.loc[X_train_user.flatten(), mlb.classes_.tolist()].values # Genre features for training data

# Fit the model with user and genre inputs
history = model.fit(
    [X_train_user, X_train_genre],  # Input: user index and genre features
    y_train,
    epochs=20,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping,reduce_learning_rate]
)

"""fungsi untuk memprediksi top n anime dengan neural network model"""

# 5. Make recommendations (example)
def neural_network_recommender(user_profile, top_n=10):
    user_idx = user_to_index.get(user_profile)
    if user_idx is None:
        return "User not found"

    unrated_anime_indices = [anime_to_index[anime] for anime in anime_ids if anime not in df_review_anime[df_review_anime['profile']==user_profile]['title'].values]

    # Get genre features for unrated anime
    unrated_anime_genres = df_review_anime.loc[[anime_to_index[anime] for anime in anime_ids if anime not in df_review_anime[df_review_anime['profile']==user_profile]['title'].values] , mlb.classes_.tolist()].values # Genre features for unrated anime

    # Prepare inputs for prediction
    user_input = np.array([user_idx] * len(unrated_anime_indices)).reshape(-1, 1)  # Repeat user_idx for each anime

    # Predict using both user and genre features
    predictions = model.predict([user_input, unrated_anime_genres])

    top_anime_indices = np.argsort(predictions, axis=0)[-top_n:][::-1]  # Get top N indices from sorted array
    top_anime = [anime_ids[idx] for idx in top_anime_indices.flatten()]

    return top_anime

"""memanggil fungsi neural_network_recommender"""

top_10_nn = neural_network_recommender("Yuez", top_n=10)

"""menampilkan top n prediksi dari neural_network_recommender"""

top_10_nn

"""## Evaluation

evaluasi mae model svd
"""

accuracy.mae(predictions_svd)

"""evaluasi rmse model svd"""

accuracy.rmse(predictions_svd)

"""evaluasi mae dan rmse model neural network"""

#For Neural Network
from sklearn.metrics import mean_absolute_error, mean_squared_error
# Prepare test data
X_test_user = X_test[:, 0].reshape(-1, 1)  # User index
X_test_genre = df_review_anime.loc[X_test_user.flatten(), mlb.classes_.tolist()].values  # Genre features for test data

# Make predictions
y_pred = model.predict([X_test_user, X_test_genre])

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))


print(f"Neural Network MAE: {mae}")
print(f"Neural Network RMSE: {rmse}")

"""menampilkan visualisasi evaluasi model neural network"""

# Plot training & validation loss values
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation MAE values
plt.figure(figsize=(10, 5))
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Model Mean Absolte Error')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()